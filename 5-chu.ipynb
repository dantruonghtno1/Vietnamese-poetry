{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel,AutoTokenizer,Trainer,TrainingArguments,GPT2Config\nfrom torch.utils.data.dataloader import DataLoader, Dataset\nimport os\nimport tqdm\nfrom random import randint\nimport glob","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-20T14:32:12.770002Z","iopub.execute_input":"2021-12-20T14:32:12.770373Z","iopub.status.idle":"2021-12-20T14:32:20.205204Z","shell.execute_reply.started":"2021-12-20T14:32:12.770287Z","shell.execute_reply":"2021-12-20T14:32:20.204462Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"files_name =[file for file in glob.glob(\"../input/tho-5-chu/5 chu/*.txt\")]\nlen(files_name)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:32:20.209075Z","iopub.execute_input":"2021-12-20T14:32:20.209346Z","iopub.status.idle":"2021-12-20T14:32:20.407221Z","shell.execute_reply.started":"2021-12-20T14:32:20.209316Z","shell.execute_reply":"2021-12-20T14:32:20.406480Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"6747"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\ntokenizer.add_tokens('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:32:20.408503Z","iopub.execute_input":"2021-12-20T14:32:20.408736Z","iopub.status.idle":"2021-12-20T14:32:27.608765Z","shell.execute_reply.started":"2021-12-20T14:32:20.408703Z","shell.execute_reply":"2021-12-20T14:32:27.608046Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb5a8f8db114432cb9252e5ac1f4cf78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/874k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"780c8acf958a4b40bca997be9589cc8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42b2475f0f1f4794a7cc83661d204bcb"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.convert_tokens_to_ids(tokenizer.pad_token)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:32:27.610853Z","iopub.execute_input":"2021-12-20T14:32:27.611929Z","iopub.status.idle":"2021-12-20T14:32:27.617603Z","shell.execute_reply.started":"2021-12-20T14:32:27.611900Z","shell.execute_reply":"2021-12-20T14:32:27.616944Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.convert_tokens_to_ids(tokenizer.bos_token)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:32:27.618973Z","iopub.execute_input":"2021-12-20T14:32:27.619453Z","iopub.status.idle":"2021-12-20T14:32:27.626017Z","shell.execute_reply.started":"2021-12-20T14:32:27.619409Z","shell.execute_reply":"2021-12-20T14:32:27.625321Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.convert_tokens_to_ids(tokenizer.eos_token)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:32:27.627382Z","iopub.execute_input":"2021-12-20T14:32:27.627928Z","iopub.status.idle":"2021-12-20T14:32:27.634399Z","shell.execute_reply.started":"2021-12-20T14:32:27.627892Z","shell.execute_reply":"2021-12-20T14:32:27.633599Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"class CustomerDataset(Dataset):\n    def __init__(self,tokenizer,file_path,block_size: int):\n        block_size = block_size - tokenizer.num_special_tokens_to_add(pair=False)\n#         print(f\"block_size = {block_size}\")\n        self.examples = []\n        self.mask = []\n        for file in file_path:\n            with open(file, encoding=\"utf-8\") as f:\n                text = f.read()\n            # text --> token-->number\n            tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n#             print(tokenized_text)\n#             while i < len(tokenized_text) - block_size + 1:\n#                 inds = tokenized_text[i : i + block_size]\n            if len(tokenized_text) < block_size:\n                inds = [tokenizer.convert_tokens_to_ids(tokenizer.bos_token)] + tokenized_text + [tokenizer.convert_tokens_to_ids(tokenizer.eos_token)] + \\\n            (block_size - len(tokenized_text)) * [tokenizer.convert_tokens_to_ids(tokenizer.pad_token)]\n                mask = [x != tokenizer.convert_tokens_to_ids(tokenizer.pad_token) for x in inds]\n#                 print(mask)\n            else:\n                inds = [tokenizer.convert_tokens_to_ids(tokenizer.bos_token)] + tokenized_text[:block_size] + [tokenizer.convert_tokens_to_ids(tokenizer.eos_token)]\n                mask = [1] * len(inds)\n#                 print(mask)\n#             print(inds)\n#             for j in range(0, len(inds)):\n#                 if inds[j]==64001:\n#                     inds = inds[j+1:] #remove the first \\n\n#                     break\n#             for j in range(len(inds)-1, 0, -1):\n#                 if inds[j]==64001:\n#                     inds = inds[:j-1] #remove \\n\n#                     break\n#             print(inds)\n#             print(f\"len inds is {len(inds)}\")\n#             self.examples.append(tokenizer.build_inputs_with_special_tokens(inds))\n            self.examples.append(inds) \n            self.mask.append(mask)\n            \n    def __len__(self):\n        return len(self.examples)\n\n    def __getitem__(self, i) -> torch.Tensor:\n        return {\n            \"input_ids\":torch.tensor(self.examples[i], dtype=torch.long), \n            \"attention_mask\":torch.tensor(self.mask[i], dtype = torch.long)\n        }\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:32:27.635834Z","iopub.execute_input":"2021-12-20T14:32:27.636299Z","iopub.status.idle":"2021-12-20T14:32:27.649071Z","shell.execute_reply.started":"2021-12-20T14:32:27.636265Z","shell.execute_reply":"2021-12-20T14:32:27.648319Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\nfrom transformers import LineByLineTextDataset, DataCollatorForLanguageModeling, LineByLineWithSOPTextDataset\n\ndef load_dataset(train_path, tokenizer):\n    train_dataset = CustomerDataset(\n          tokenizer=tokenizer,\n          file_path=train_path,\n          block_size= 256)#256\n    \n    data_collator = DataCollatorForLanguageModeling(\n        tokenizer=tokenizer, mlm=False,\n    )\n    return train_dataset,data_collator","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:32:27.650370Z","iopub.execute_input":"2021-12-20T14:32:27.650900Z","iopub.status.idle":"2021-12-20T14:32:27.691333Z","shell.execute_reply.started":"2021-12-20T14:32:27.650864Z","shell.execute_reply":"2021-12-20T14:32:27.690699Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset,data_collator = load_dataset(files_name,tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:32:27.692522Z","iopub.execute_input":"2021-12-20T14:32:27.692741Z","iopub.status.idle":"2021-12-20T14:32:52.338893Z","shell.execute_reply.started":"2021-12-20T14:32:27.692710Z","shell.execute_reply":"2021-12-20T14:32:52.338204Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:32:52.341599Z","iopub.execute_input":"2021-12-20T14:32:52.341865Z","iopub.status.idle":"2021-12-20T14:32:52.385565Z","shell.execute_reply.started":"2021-12-20T14:32:52.341831Z","shell.execute_reply":"2021-12-20T14:32:52.384012Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = GPT2LMHeadModel.from_pretrained('danghuy1999/gpt2-viwiki')\nrand_weight = torch.rand(model.lm_head.weight.shape)\nmodel.lm_head.weight = torch.nn.parameter.Parameter(rand_weight)\ntask_gpt2 = {\"text-generation\": {\"do_sample\": True, \"max_length\": 256}} \nconfiguration = GPT2Config(vocab_size=64002, n_positions=260, n_ctx=260,\n                           task_specific_params=task_gpt2,\n                           eos_token_id = 2,\n                           bos_token_id = 0,\n                           pad_token_id = 1,\n                           sep_token_id = 2,)\nmodel = GPT2LMHeadModel(configuration)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:32:52.386919Z","iopub.execute_input":"2021-12-20T14:32:52.387200Z","iopub.status.idle":"2021-12-20T14:33:24.149501Z","shell.execute_reply.started":"2021-12-20T14:32:52.387151Z","shell.execute_reply":"2021-12-20T14:33:24.148749Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/916 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c26b5b114a084f40846e417b13734558"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/487M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41920f1c14564b9db6564519fe52ecfa"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at danghuy1999/gpt2-viwiki were not used when initializing GPT2LMHeadModel: ['multiple_choice_head.summary.bias', 'multiple_choice_head.summary.weight']\n- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"model = model.from_pretrained('../input/5chusaved')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:33:24.150891Z","iopub.execute_input":"2021-12-20T14:33:24.151149Z","iopub.status.idle":"2021-12-20T14:33:32.443306Z","shell.execute_reply.started":"2021-12-20T14:33:24.151117Z","shell.execute_reply":"2021-12-20T14:33:32.442585Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from transformers.trainer_callback import TrainerCallback\nfrom transformers import pipeline\n\ntraining_args = TrainingArguments(\n    output_dir=\"5-chu\", \n    overwrite_output_dir=True,\n    num_train_epochs=20,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=16, \n    save_steps=1000,\n    save_total_limit = 2,\n    warmup_steps=1000, \n    logging_steps=100,\n    report_to=\"wandb\"\n    )","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:33:32.444827Z","iopub.execute_input":"2021-12-20T14:33:32.445066Z","iopub.status.idle":"2021-12-20T14:33:32.475178Z","shell.execute_reply.started":"2021-12-20T14:33:32.445033Z","shell.execute_reply":"2021-12-20T14:33:32.474575Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda')\ntrainer = Trainer(\n    model=model, \n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:33:32.476199Z","iopub.execute_input":"2021-12-20T14:33:32.476448Z","iopub.status.idle":"2021-12-20T14:33:33.179426Z","shell.execute_reply.started":"2021-12-20T14:33:32.476412Z","shell.execute_reply":"2021-12-20T14:33:33.178565Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:33:33.180839Z","iopub.execute_input":"2021-12-20T14:33:33.181082Z","iopub.status.idle":"2021-12-20T16:13:40.913580Z","shell.execute_reply.started":"2021-12-20T14:33:33.181046Z","shell.execute_reply":"2021-12-20T16:13:40.912874Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"***** Running training *****\n  Num examples = 6747\n  Num Epochs = 20\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 16880\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/dantruonghtno1/huggingface/runs/csw2eb7i\" target=\"_blank\">5-chu</a></strong> to <a href=\"https://wandb.ai/dantruonghtno1/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='16880' max='16880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [16880/16880 1:39:12, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.331600</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.329900</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.334500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.345700</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.361900</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.387000</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.413900</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.442900</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.453900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.478000</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.528100</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.558400</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.577500</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.608700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.631200</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.629200</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.620400</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.485600</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.512300</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.524000</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.545400</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.534200</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.560200</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.573500</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.573300</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.455500</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.424900</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.440300</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.442300</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.465000</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.474000</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.482900</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.480900</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.444200</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.352700</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.365900</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.377400</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.387900</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>0.391800</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.394400</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>0.410700</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.405000</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>0.337500</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.314700</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.315500</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>0.330500</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>0.328500</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>0.333700</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>0.349100</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.348600</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>0.320000</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>0.261800</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>0.277900</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>0.283800</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.289800</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>0.295300</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>0.296900</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>0.298100</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>0.300800</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.236600</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>0.239200</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>0.248900</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>0.256000</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>0.252800</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.256700</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>0.259400</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>0.261700</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>0.235800</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>0.216800</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.217300</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>0.222400</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>0.227500</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>0.230800</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>0.233500</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.239000</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>0.233600</td>\n    </tr>\n    <tr>\n      <td>7700</td>\n      <td>0.190600</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>0.196300</td>\n    </tr>\n    <tr>\n      <td>7900</td>\n      <td>0.199100</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.206200</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>0.237000</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>0.239100</td>\n    </tr>\n    <tr>\n      <td>8300</td>\n      <td>0.235900</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>0.238400</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.211700</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>0.196200</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>0.196500</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>0.203500</td>\n    </tr>\n    <tr>\n      <td>8900</td>\n      <td>0.203800</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.212400</td>\n    </tr>\n    <tr>\n      <td>9100</td>\n      <td>0.211000</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>0.211400</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>0.208000</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>0.178200</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.184700</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>0.180300</td>\n    </tr>\n    <tr>\n      <td>9700</td>\n      <td>0.187000</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>0.187600</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>0.187800</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.192500</td>\n    </tr>\n    <tr>\n      <td>10100</td>\n      <td>0.191900</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>0.166400</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>0.165400</td>\n    </tr>\n    <tr>\n      <td>10400</td>\n      <td>0.168900</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.169500</td>\n    </tr>\n    <tr>\n      <td>10600</td>\n      <td>0.172600</td>\n    </tr>\n    <tr>\n      <td>10700</td>\n      <td>0.173700</td>\n    </tr>\n    <tr>\n      <td>10800</td>\n      <td>0.176200</td>\n    </tr>\n    <tr>\n      <td>10900</td>\n      <td>0.176500</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.167200</td>\n    </tr>\n    <tr>\n      <td>11100</td>\n      <td>0.152600</td>\n    </tr>\n    <tr>\n      <td>11200</td>\n      <td>0.153400</td>\n    </tr>\n    <tr>\n      <td>11300</td>\n      <td>0.157300</td>\n    </tr>\n    <tr>\n      <td>11400</td>\n      <td>0.163400</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.159000</td>\n    </tr>\n    <tr>\n      <td>11600</td>\n      <td>0.163100</td>\n    </tr>\n    <tr>\n      <td>11700</td>\n      <td>0.164000</td>\n    </tr>\n    <tr>\n      <td>11800</td>\n      <td>0.163100</td>\n    </tr>\n    <tr>\n      <td>11900</td>\n      <td>0.144100</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.144200</td>\n    </tr>\n    <tr>\n      <td>12100</td>\n      <td>0.145000</td>\n    </tr>\n    <tr>\n      <td>12200</td>\n      <td>0.144000</td>\n    </tr>\n    <tr>\n      <td>12300</td>\n      <td>0.149900</td>\n    </tr>\n    <tr>\n      <td>12400</td>\n      <td>0.149700</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.152600</td>\n    </tr>\n    <tr>\n      <td>12600</td>\n      <td>0.148200</td>\n    </tr>\n    <tr>\n      <td>12700</td>\n      <td>0.142800</td>\n    </tr>\n    <tr>\n      <td>12800</td>\n      <td>0.133800</td>\n    </tr>\n    <tr>\n      <td>12900</td>\n      <td>0.138300</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.138900</td>\n    </tr>\n    <tr>\n      <td>13100</td>\n      <td>0.140500</td>\n    </tr>\n    <tr>\n      <td>13200</td>\n      <td>0.139800</td>\n    </tr>\n    <tr>\n      <td>13300</td>\n      <td>0.141600</td>\n    </tr>\n    <tr>\n      <td>13400</td>\n      <td>0.143700</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.141100</td>\n    </tr>\n    <tr>\n      <td>13600</td>\n      <td>0.127700</td>\n    </tr>\n    <tr>\n      <td>13700</td>\n      <td>0.128600</td>\n    </tr>\n    <tr>\n      <td>13800</td>\n      <td>0.129700</td>\n    </tr>\n    <tr>\n      <td>13900</td>\n      <td>0.130300</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.129800</td>\n    </tr>\n    <tr>\n      <td>14100</td>\n      <td>0.134300</td>\n    </tr>\n    <tr>\n      <td>14200</td>\n      <td>0.134900</td>\n    </tr>\n    <tr>\n      <td>14300</td>\n      <td>0.135200</td>\n    </tr>\n    <tr>\n      <td>14400</td>\n      <td>0.125300</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.124300</td>\n    </tr>\n    <tr>\n      <td>14600</td>\n      <td>0.120800</td>\n    </tr>\n    <tr>\n      <td>14700</td>\n      <td>0.125100</td>\n    </tr>\n    <tr>\n      <td>14800</td>\n      <td>0.126400</td>\n    </tr>\n    <tr>\n      <td>14900</td>\n      <td>0.126600</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.127900</td>\n    </tr>\n    <tr>\n      <td>15100</td>\n      <td>0.127000</td>\n    </tr>\n    <tr>\n      <td>15200</td>\n      <td>0.126600</td>\n    </tr>\n    <tr>\n      <td>15300</td>\n      <td>0.116400</td>\n    </tr>\n    <tr>\n      <td>15400</td>\n      <td>0.120700</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>0.117200</td>\n    </tr>\n    <tr>\n      <td>15600</td>\n      <td>0.122400</td>\n    </tr>\n    <tr>\n      <td>15700</td>\n      <td>0.122400</td>\n    </tr>\n    <tr>\n      <td>15800</td>\n      <td>0.125700</td>\n    </tr>\n    <tr>\n      <td>15900</td>\n      <td>0.122800</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>0.124400</td>\n    </tr>\n    <tr>\n      <td>16100</td>\n      <td>0.126600</td>\n    </tr>\n    <tr>\n      <td>16200</td>\n      <td>0.122700</td>\n    </tr>\n    <tr>\n      <td>16300</td>\n      <td>0.121300</td>\n    </tr>\n    <tr>\n      <td>16400</td>\n      <td>0.121300</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>0.121800</td>\n    </tr>\n    <tr>\n      <td>16600</td>\n      <td>0.122100</td>\n    </tr>\n    <tr>\n      <td>16700</td>\n      <td>0.120400</td>\n    </tr>\n    <tr>\n      <td>16800</td>\n      <td>0.121100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to 5-chu/checkpoint-1000\nConfiguration saved in 5-chu/checkpoint-1000/config.json\nModel weights saved in 5-chu/checkpoint-1000/pytorch_model.bin\nSaving model checkpoint to 5-chu/checkpoint-2000\nConfiguration saved in 5-chu/checkpoint-2000/config.json\nModel weights saved in 5-chu/checkpoint-2000/pytorch_model.bin\nSaving model checkpoint to 5-chu/checkpoint-3000\nConfiguration saved in 5-chu/checkpoint-3000/config.json\nModel weights saved in 5-chu/checkpoint-3000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-1000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-4000\nConfiguration saved in 5-chu/checkpoint-4000/config.json\nModel weights saved in 5-chu/checkpoint-4000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-2000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-5000\nConfiguration saved in 5-chu/checkpoint-5000/config.json\nModel weights saved in 5-chu/checkpoint-5000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-3000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-6000\nConfiguration saved in 5-chu/checkpoint-6000/config.json\nModel weights saved in 5-chu/checkpoint-6000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-4000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-7000\nConfiguration saved in 5-chu/checkpoint-7000/config.json\nModel weights saved in 5-chu/checkpoint-7000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-5000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-8000\nConfiguration saved in 5-chu/checkpoint-8000/config.json\nModel weights saved in 5-chu/checkpoint-8000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-6000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-9000\nConfiguration saved in 5-chu/checkpoint-9000/config.json\nModel weights saved in 5-chu/checkpoint-9000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-7000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-10000\nConfiguration saved in 5-chu/checkpoint-10000/config.json\nModel weights saved in 5-chu/checkpoint-10000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-8000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-11000\nConfiguration saved in 5-chu/checkpoint-11000/config.json\nModel weights saved in 5-chu/checkpoint-11000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-9000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-12000\nConfiguration saved in 5-chu/checkpoint-12000/config.json\nModel weights saved in 5-chu/checkpoint-12000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-10000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-13000\nConfiguration saved in 5-chu/checkpoint-13000/config.json\nModel weights saved in 5-chu/checkpoint-13000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-11000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-14000\nConfiguration saved in 5-chu/checkpoint-14000/config.json\nModel weights saved in 5-chu/checkpoint-14000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-12000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-15000\nConfiguration saved in 5-chu/checkpoint-15000/config.json\nModel weights saved in 5-chu/checkpoint-15000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-13000] due to args.save_total_limit\nSaving model checkpoint to 5-chu/checkpoint-16000\nConfiguration saved in 5-chu/checkpoint-16000/config.json\nModel weights saved in 5-chu/checkpoint-16000/pytorch_model.bin\nDeleting older checkpoint [5-chu/checkpoint-14000] due to args.save_total_limit\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=16880, training_loss=0.25742239759996605, metrics={'train_runtime': 6007.7006, 'train_samples_per_second': 22.461, 'train_steps_per_second': 2.81, 'total_flos': 1.762937339904e+16, 'train_loss': 0.25742239759996605, 'epoch': 20.0})"},"metadata":{}}]},{"cell_type":"code","source":"ls 5-chu/","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:13:40.915009Z","iopub.execute_input":"2021-12-20T16:13:40.915740Z","iopub.status.idle":"2021-12-20T16:13:41.775858Z","shell.execute_reply.started":"2021-12-20T16:13:40.915697Z","shell.execute_reply":"2021-12-20T16:13:41.774848Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34mcheckpoint-15000\u001b[0m/  \u001b[01;34mcheckpoint-16000\u001b[0m/\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom transformers import pipeline\npoem = pipeline('text-generation', model=\"./5-chu/checkpoint-16000/\", tokenizer=tokenizer)\n#Test\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:13:41.779089Z","iopub.execute_input":"2021-12-20T16:13:41.779358Z","iopub.status.idle":"2021-12-20T16:13:43.936036Z","shell.execute_reply.started":"2021-12-20T16:13:41.779323Z","shell.execute_reply":"2021-12-20T16:13:43.935365Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"loading configuration file ./5-chu/checkpoint-16000/config.json\nModel config GPT2Config {\n  \"_name_or_path\": \"../input/5chusaved\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 0,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 2,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 260,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 260,\n  \"pad_token_id\": 1,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"sep_token_id\": 2,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 256\n    }\n  },\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.12.5\",\n  \"use_cache\": true,\n  \"vocab_size\": 64002\n}\n\nloading configuration file ./5-chu/checkpoint-16000/config.json\nModel config GPT2Config {\n  \"_name_or_path\": \"../input/5chusaved\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 0,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 2,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 260,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 260,\n  \"pad_token_id\": 1,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"sep_token_id\": 2,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 256\n    }\n  },\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.12.5\",\n  \"use_cache\": true,\n  \"vocab_size\": 64002\n}\n\nloading weights file ./5-chu/checkpoint-16000/pytorch_model.bin\nAll model checkpoint weights were used when initializing GPT2LMHeadModel.\n\nAll the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./5-chu/checkpoint-16000/.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"a = poem('<s>mẹ ơi')\nprint(a[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:13:43.937142Z","iopub.execute_input":"2021-12-20T16:13:43.937419Z","iopub.status.idle":"2021-12-20T16:13:50.211570Z","shell.execute_reply.started":"2021-12-20T16:13:43.937380Z","shell.execute_reply":"2021-12-20T16:13:50.210864Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"<s>mẹ ơi con rất sợ \n mỗi khi mùa xuân về \n tóc mẹ lại thêm bạc \n lưng mẹ cũng thêm còng \n mẹ ơi con rất sợ \n mỗi năm mùa xuân về \n mẹ ngồi ngóng con trẻ \n có đứa nào về chưa \n mẹ ơi con vẫn sợ \n nhưng mùa xuân vần về \n mẹ lại thêm tuổi mới \n chuối chín cây sắp rơi \n mẹ ơi con vẫn sợ \n rồi một khi xuân về \n không còn thấy bóng mẹ \n trước cổng ngồi ngóng con\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}